# Zookeeper持久化方式简介

由于Zookeeper和Redis一样，数据都是存储在内存中，所以也需要进行持久化操作。不然当Zookeeper服务挂掉之后，其中所存储的数据也就没有了。

**Zookeeper持久化的方式有两种，分为snapshot文件和log文件。**

当我们想使用其中一种持久化方案的时候，就要知道在哪里指定这个文件的生成路径以及生成之后的文件路径情况。

在zoo.cfg文件中可通过指定dataDir指定snapshot文件路径以及通过指定dataLogDir指定log文件路径。

正如下图所示，不管是snapshot还是log文件，都会在指定路径下生成version-2目录，然后在此目录下生成snapshot文件或者log文件。

log 是负责顺序记录每一个写请求到文件，snapshot 则是直接将整个内存对象持久化至文件中。假设我现在zoo.cfg的配置是这样：

```
dataDir=/usr/local/zookeeper-3.7.0/dkdata/snapshot
dataLogDir=/usr/local/zookeeper-3.7.0/dkdata/log
```

当 ZK 启动后会基于上面两个路径继续创建version-2子路径，之后的文件都会在该子路径下创建

```
/usr
 ├──local
        └──zookeeper-3.7.0 
                          ├──dkdata
                                    ├──snapshot
    		                            └──version-2
    				                         └── ...
                                    └──log
    		                            └──version-2
    				                         └── ...
```

------

------

## Snapshot持久化

Snapshot持久化也称为称为快照持久化，类似于Redis中的RDB持久化。即间隔一定时间后把当前数据进行快照备份后，在指定路径下生成快照文件。

snapshot 文件名的格式是这样 `snapshot.{zxid}` ，zxid 对应当是创建该文件时的最大 zxid，假设现在创建是最大 zxid 是 0，那目录结构会是这样：

```
/usr
 ├──local
        └──zookeeper-3.7.0 
                          ├──dkdata
                                    ├──snapshot
    		                            └──version-2
    				                       └──snapshot.0
```

那么如何判断触发快照持久化的条件呢？

首先有两个配置 `zookeeper.snapCount` （默认 100000）和 `zookeeper.snapSizeLimitInKb`（默认 4194304 单位是KB，相当于 4 GB）在启动后会基于这两个配置分别生成两个随机数，假设上述的配置是按照默认的设置，这两个随机数的范围就是：

```
randRoll = [0, 50000]
randSize = [0, 4194304 * 1024 / 2]
```

可以简单的认为就是上述两个配置的一半之内的随机数，至于 `randSize` 为什么要乘以 1024 因为最终文件计算大小是以 byte 作为单位的。

而是否快照就是取决于上面两个随机数，有两个条件：

- 当前写请求的数量达到了 `zookeeper.snapCount` 的一半并加上 `randRoll` 的数量
- 当前 log 文件的大小达到了 `zookeeper.snapSizeLimitInKb` 的一半并加上 `randSize` 的大小

上述条件满足任意一个条件后就会重置上面的两个随机数，并开始生成快照，**生成快照这个过程是启动一个子线程去创建的。**

------

#### Snapshot持久化流程

(1)每完成一次事务操作Zookeeper都会检查是否达到snapCount设置也就是来判断是否需要进行快照操作，因为快照本身对机器性能有影响，要避免集群中所有节点都进行快照

(2)如果要进行快照操作，首先就需要对事务日志进行截断然后切换，所以事务日志写满不是以64M为标准而是以事务条数为标准的。

(3)创建异步线程来执行快照操作

(4)从ZK主进程中获取全量数据和会话，因为要保存内存所有数据节点信息和会话信息

(5)生成快照名称，会根据已提交的最大ZXID来生成快照名称

(6)数据序列化，首先会序列化文件头信息（魔数、版本、dbid信息），然后对会话信息和DataTree（Zookeeper内存数据的核心一个树形数据结构，代表内存完整数据）分别序列化，同时生成一个校验和，然后一起写入数据文件中

------

## Log持久化

log持久化顾名思义就是使用事务日志进行持久化。类似于Redis的AOF持久化，即每响应一个写请求即把此请求写入到事务日志文件中。

log 文件名的格式是这样 `log.{zxid}` zxid 对应当时创建该文件时的最大 zxid，假设现在创建时 zxid 为 0，那目录结构会是这样：

```
/usr
 ├──local
        └──zookeeper-3.7.0 
                          ├──dkdata
                                    ├──log
    		                            └──version-2
    				                       └──log.1
```

这个 `log.0` 文件创建的时机你也可以简单的理解为当服务端收到第一个写请求的时候，而且当创建完成后，并不能直接将数据写入，而是要先写一些文件头的字段，比如魔数，版本号等元信息。

那么如何判断触发事务日志持久化的条件呢？

首先我们得知道`zookeeper.txnLogSizeLimitInKb` 这个环境变量配置，默认是 -1(也就是64MB)，这个配置限制了 log 单个文件大小（单位是 KB）

一旦ZK发现正在写入的事务日志文件剩余空间大小小于4KB的时候，就会进行预先分配空间策略进行扩容（也就是下一写请求时会创建一个新的最大zxid为后缀的log文件）。

**注意：除了事务日志文件剩余空间剩余不足4KB之外，当快照持久化被触发的时候，也会强制进行预先分配空间策略进行扩容。**

------

#### log持久化流程

(1)当需要写入事务日志的时候Zookeeper会判断它是否和一个可写入的事务日志相关联，如果关联就写入，如果没有则用该事务的事务ID来创建一个事务日志，同时将这个写请求事务文件流放入到一个集合中（streamsToFlush），这个集合中记录的是当前需要强刷数据到磁盘的文件流（因为操作系统通常有延迟写入机制，对于Linux系统强刷等于调用fsync）。**为什么需要这个集合？因为每条写请求都立马写入事务日志，也就是频繁 flush 到磁盘，就会消耗大量磁盘 IO**。

(2)事务日志文件采用预先分配空间策略，这样为了保证单一事务日志文件所占用的磁盘块是连续的，这也是为了提高性能。当Zookeeper发现当前正在写入的事务日志文件空间不足4KB时，就会启动预先分配空间策略进行扩容。第一次使用事务日志或者事务日志达到切割条数（snapCount参数触发快照）会启动预先分配策略；其他时候只要发现当前使用的事务日志空余不足4KB就进行扩容，扩容时使用0进行填充。

(3)确保日志文件空间够之后就需要对进行写请求事务序列化操作，最终产生一个字节数组。主要对事务头（TxnHeader）和事务体（Record）进行序列化。

(4)根据序列化后的字节数据计算一个校验和

(5)将字节数组和校验写入到文件流中。

(6)由于该事务日志的文件流在集合中，这时候就会从集合里面取出文件流强刷落盘。

------

------

## Zookeepper单体环境下恢复过程

我们先来看看持久化的环境情况：

在 ZK 启动的时候就会尝试读取 `dataDir` 和 `dataLogDir` 这两个目录下的文件，假设在这两个路径下的文件是：

```
/usr
 ├──local
        └──zookeeper-3.7.0 
                          ├──dkdata
                                    ├──snapshot
    		                            └──version-2
    				                     └── snapshot.0
    				                     └── snapshot.54
    				                     └── snapshot.125

                                    ├──log
    		                            └──version-2
    				                     └── log.0
    				                     └── log.6
    				                     └── log.48
    				                     └── log.110
    				                     └── log.130
```

现在 ZK 服务端启动后，会先从 snapshot 的目录中找到 zxid 最大的那个文件，也就是snapshot.125这个快照文件，通过其恢复Zk的DataTree结构和拥有的会话数据，然后在去寻找zxid为125附近的log文件，也就是log.110和log130文件来进行DataTree中的部分Znode数据的恢复。

为什么需要寻找最大zxid附近的log文件呢？

**因为文件名中的110只是说明这个文件建立的时候，最大的 zxid 是 110，但是文件中记录的写请求是很有可能会大于 11-0的。所以为了保险起见我们获取到110的log文件。**